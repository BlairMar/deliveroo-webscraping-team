{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deliveroo Core Web Scraper\n",
    "\n",
    "From each page should scrape: restaurant img, rating, name, cuisine, opening, dietary, distance, delivery price\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By #importing necessary modules.\n",
    "from time import sleep\n",
    "import requests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Draft of Web Scraper (functions only)\n",
    "\n",
    "The first run of the web scraper is built with only the new implementation in mind and is not built within the class.  \n",
    "\n",
    "After there's a working version of the new implementation, it will be added to the class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://deliveroo.co.uk/menu/london/whitechapel-editions/dishoom-shoreditch?day=today&geohash=gcpvns0fhrh1&sp_id=NzU0ZmVmNjktOTBkZi00YzY2LTg5YjUtMjM1NWYwODFhYmU3LDlhMzAzODM1LTkxYzQtNDZjNC04MTMyLTBhZjM3ZGI0MDZlNg%3D%3D&time=ASAP\")\n",
    "#https://deliveroo.co.uk/menu/london/victoria/joe-and-the-juice-westminster?day=today&geohash=gcpuuwmssw3u&time=ASAP"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "Summary_info = driver.find_elements(By.XPATH, '//*[@id=\"app-element\"]/div/div[2]/div[1]/div[2]/div/div[1]')\n",
    "\n",
    "\n",
    "def Summary_Data():      \n",
    "    \n",
    "    rawdata = Summary_info[0].text.splitlines()\n",
    "    sorteddata = {'Name':rawdata[0], 'Rating':None, 'Tags': [], 'Address':None}\n",
    "    lower_bound, upper_bound = 0 ,0\n",
    "\n",
    "    for item in rawdata:\n",
    "        if '+ rating' in item:\n",
    "            sorteddata['Rating'] = item\n",
    "            lower_bound = rawdata.index(item)+1\n",
    "\n",
    "        elif 'View map' in item:\n",
    "            upper_bound = rawdata.index(item)\n",
    "            sorteddata['Address'] = rawdata[upper_bound - 1]\n",
    "            upper_bound -= 2 # setting upper bound to 2 elements view map appears. \n",
    "\n",
    "    sorteddata['Tags'] = [item for item in rawdata[lower_bound:upper_bound]]   \n",
    "\n",
    "\n",
    "    return(sorteddata) # at the moment, returns a list of all the data in the summary information. \n",
    "\n",
    "Image_info = driver.find_elements(By.XPATH,'//*[@class = \"restaurant__image\"]//*')\n",
    "\n",
    "def Image_Download():\n",
    "    txt = Image_info[1].get_attribute(\"style\")\n",
    "    src = txt.split('\"')\n",
    "    url = src[1]\n",
    "    path = f'{Summary_Data()[0][0]}.jpg'\n",
    "    img_data = requests.get(url).content\n",
    "    with open(path, 'wb') as handler:\n",
    "         handler.write(img_data)\n",
    "    \n",
    "    return(url)    \n",
    "\n",
    "Summary_Data()\n",
    "#Image_Download()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Name': 'HomeWhitechapel EditionsDishoom',\n",
       " 'Rating': '4.8(500+ ratings)',\n",
       " 'Tags': ['Curry', 'Indian', 'Drinks', 'Salads', 'Alcohol', 'Asian', 'Halal'],\n",
       " 'Address': '10 Assembly Passage, Whitechapel, London, E14UT'}"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second draft (Class)\n",
    "\n",
    "Following the implementation of a new feature in the first draft, features are added here to the main class. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "\n",
    "class DeliverooScraper:\n",
    "    data = []\n",
    "\n",
    "    def __init__(self) -> None: #initialising Selenium and starting the webdriver.\n",
    "        self.driver = webdriver.Chrome()\n",
    "    \n",
    "    def scrape(self):\n",
    "        #launches web browser and calls the next method. \n",
    "        self.driver.get(\n",
    "        \"https://deliveroo.co.uk/menu/london/fulham/mamino-fulham?day=today&geohash=gcpuuw8wdq1m&time=ASAP\")\n",
    "        \n",
    "\n",
    "\n",
    "    def getSummary(self):\n",
    "        Summary_info = self.driver.find_elements(By.XPATH, '//*[@id=\"app-element\"]/div/div[2]/div[1]/div[2]/div/div[1]')\n",
    "\n",
    "        for info in Summary_info: #Looping over list of summary information about the restaraunt.     \n",
    "            \n",
    "            text = info.text\n",
    "            DeliverooScraper.data = text.splitlines()\n",
    "                             #splits the string at new lines and stores as a list. \n",
    "                            #at some point, we need to implement storing and organising the data in dictionaries.\n",
    "      \n",
    "\n",
    "        return DeliverooScraper.data #defined as a global variable. \n",
    "\n",
    "    \n",
    "    def getPicture(self):\n",
    "        Image_info = self.driver.find_elements(By.XPATH,'//*[@id=\"app-element\"]/div/div[2]/div[1]/div[2]/div/div[2]/div[1]/div/div')\n",
    "        #Accessing the image info using XPATH. Probably a cleaner way of doing this. \n",
    "\n",
    "        txt = Image_info[0].get_attribute(\"style\")\n",
    "        src = txt.split('\"') #Only need the url so the code splits string at \". \n",
    "        url = src[1]\n",
    "        name = DeliverooScraper.data[0]\n",
    "        path = f'{name}.jpg' #Path is created from the first element of the list returned by \n",
    "                                          #Summary Data. \n",
    "        \n",
    "        #Downloading image from url. \n",
    "        image = requests.get(url).content\n",
    "        with open(path, 'wb') as handler:\n",
    "         handler.write(image)\n",
    "    \n",
    "        return(url)    \n",
    "\n",
    "\n",
    "Scraper = DeliverooScraper()\n",
    "        \n",
    "Scraper.scrape()\n",
    "\n",
    "print(Scraper.getSummary())\n",
    "\n",
    "Scraper.getPicture()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['HomeFulhamMamino', 'Mamino - Fulham', '4.4(500+ ratings)', 'Pasta', 'Dessert', 'Vegan Friendly', 'Gluten Free', 'Mediterranean', 'Italian', 'Drinks', 'Open until 23:59', \"One KCN, Unit 5, The Talina Centre, 23a Bagley's Lane, London, SW62BW\", 'View map', 'Restaurant info', 'Map, allergens and hygiene rating', '50% off entire menu', 'T&Cs apply']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://rs-menus-api.roocdn.com/images/3c465ea8-58c3-4263-9bd6-f3a4ada66738/image.jpeg?width=370&height=160&auto=webp&format=jpg&fit=crop&v='"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://rs-menus-api.roocdn.com/images/3c465ea8-58c3-4263-9bd6-f3a4ada66738/image.jpeg?width=319&height=160&auto=webp&format=jpg&fit=crop&v='"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "mydic ={'rating':[]}\n",
    "newlist = ['thing','other','rating 3frss','bob']\n",
    "\n",
    "for item in newlist:\n",
    "    if 'rating' in item:\n",
    "        mydic['rating'].append(item)\n",
    "\n",
    "print(mydic)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'rating': ['rating 3frss']}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json   \n",
    " \n",
    "check ='Dishom'\n",
    "   \n",
    "def _duplication_check(check):\n",
    "    with open ('data/LS12 5NJ/data.json', 'r') as file:\n",
    "        existing_data = json.load(file)\n",
    "    if check in existing_data.__str__():\n",
    "        print(existing_data)\n",
    "        return True\n",
    "    else:\n",
    "        print('False')\n",
    "        return False\n",
    "\n",
    "_duplication_check(check)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2efe80bebba179815d24ae5cd38278420ad8f30607b4187cd5081336dd8290d8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}